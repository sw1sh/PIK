{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1309,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = pd.read_csv('input/flat.csv', encoding='cp1251', index_col=['bulk_id', 'spalen', 'id_flatwork'], \n",
    "                   parse_dates=['date_settle', 'date_salestart', 'flat_startsale', 'sale']).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1156,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/train.csv', encoding='cp1251', index_col=['bulk_id', 'spalen', 'date1'], parse_dates=['date1']).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1158,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('input/test.csv', encoding='cp1251', index_col=['bulk_id', 'spalen', 'date1'], parse_dates=['date1']).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1284,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['value'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1285,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1159,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = pd.read_csv('input/status.csv',  encoding='cp1251', index_col=['id_flatwork'], parse_dates=['datefrom', 'dateto']).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1160,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = pd.read_csv('input/price.csv', index_col=['id_flatwork'], parse_dates=['datefrom']).sort_values('datefrom', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1165,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date = pd.to_datetime('2015-07-01')\n",
    "max_date = pd.to_datetime('2018-05-01')\n",
    "\n",
    "dates = pd.date_range(min_date, max_date, freq=pd.offsets.MonthBegin(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1166,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = dates.map(lambda date: pd.DataFrame({'date1': date, \n",
    "                                              'pricem2': price[price['datefrom'] < date].groupby(level=0)['pricem2'].first()}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1167,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = pd.concat(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_active = [100000001, 100000003, 100000006, 100000010, 100000020, 100000021]\n",
    "stat_reserved = [100000003, 100000020, 100000021] # ['Зарезервирован под клиента', 'Платное бронирование', 'Онлайн бронирование']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1169,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_active = status[status['stat'].isin(stat_active)]\n",
    "status_reserved = status[status['stat'].isin(stat_reserved)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1170,
   "metadata": {},
   "outputs": [],
   "source": [
    "statuses_active = pd.concat(dates.map(lambda date: pd.DataFrame(\n",
    "    {'date1': date, \n",
    "     'stat': status_active[status_active['datefrom'] < date].groupby(level=0)['stat'].first()})))\n",
    "statuses_reserved = pd.concat(dates.map(lambda date: pd.DataFrame(\n",
    "    {'date1': date, \n",
    "     'stat': status_reserved[status_reserved['datefrom'] < date].groupby(level=0)['stat'].first()})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1310,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_prices = pd.merge(flat.reset_index()[['bulk_id', 'spalen', 'id_flatwork', 'floor', 'square', 'flat_startsale', 'sale']], \n",
    "                       prices.reset_index(), on=['id_flatwork'], how='left')\n",
    "\n",
    "flat_prices = flat_prices[flat_prices['pricem2'] != 1.0]\n",
    "\n",
    "flat_prices = flat_prices[(flat_prices['flat_startsale'] <= flat_prices['date1']) & \n",
    "            (flat_prices['sale'] > flat_prices['date1'])]\n",
    "\n",
    "flat_active = pd.merge(flat_prices, \n",
    "                     statuses_active.reset_index(), on=['id_flatwork', 'date1'], how='left').dropna()\n",
    "flat_reserved = pd.merge(flat_prices, \n",
    "                     statuses_reserved.reset_index(), on=['id_flatwork', 'date1'], how='left').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1311,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_active.to_csv('output/flat_active.csv', index=False)\n",
    "flat_reserved.to_csv('output/flat_reserved.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1312,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_prices = flat_prices.groupby('id_flatwork')['pricem2'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(df):\n",
    "    names = {'flats_left': len(df), \n",
    "             'max_fl': df['floor'].max(),\n",
    "             'min_fl': df['floor'].min(),\n",
    "             'mean_fl': df['floor'].mean(),\n",
    "             'max_sq': df['square'].max(),\n",
    "             'min_sq': df['square'].min(),\n",
    "             'sum_sq': df['square'].sum(),\n",
    "             'mean_sq': df['square'].mean(),\n",
    "             'max_price': df['pricem2'].max(),\n",
    "             'min_price': df['pricem2'].min(),\n",
    "             'mean_price': df['pricem2'].mean()}\n",
    "    return pd.Series(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1314,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat['months_to_sale'] = flat.groupby(level=[0, 1]) \\\n",
    ".apply(lambda df: (df['sale'].sort_values().dt.to_period('M') - df['sale'].min().to_period('M'))) \\\n",
    ".reset_index([0, 1], drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1315,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = flat.join(mean_prices).dropna(subset=['pricem2', 'months_to_sale'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1316,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat[flat['sale'] != flat['sale'].max()].reset_index() \\\n",
    "  .to_csv('input/flat_train.csv', index=False, columns=pd.read_csv('input/flat.csv', encoding='cp1251').columns.drop('sale').tolist() + ['pricem2', 'months_to_sale'])\n",
    "\n",
    "flat[flat['sale'] == flat['sale'].max()].reset_index() \\\n",
    "  .to_csv('input/flat_test.csv', index=False, columns=pd.read_csv('input/flat.csv', encoding='cp1251').columns.drop('sale').tolist() + ['pricem2', 'months_to_sale'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_flat_features(df):\n",
    "    flat_features = df.groupby(['bulk_id', 'spalen', 'date1']).apply(aggregate).sort_index()\n",
    "\n",
    "    flat_features['flats_sold'] = flat_features.groupby(level=[0,1])['flats_left'].apply(lambda x: x[::-1].diff()[::-1].abs())\n",
    "    flat_features['flats_value'] = flat_features.groupby(level=[0,1])['sum_sq'].apply(lambda x: x[::-1].diff()[::-1].abs())\n",
    "\n",
    "    flat_features['flats_sold_lag'] = flat_features.groupby(level=[0,1])['flats_sold'].apply(lambda x: x.shift(1))\n",
    "    flat_features['flats_value_lag'] = flat_features.groupby(level=[0,1])['flats_value'].apply(lambda x: x.shift(1))\n",
    "\n",
    "    flat_features.index.set_levels(flat_features.index.levels[1].astype(int), level=1, inplace=True)\n",
    "\n",
    "    flat_features = flat_features.reindex(train_test.index)\n",
    "\n",
    "    flat_features.loc[train_test.index, 'value'] = train_test['value']\n",
    "\n",
    "    flat_features['value_lag'] = flat_features.groupby(level=[0,1])['value'].apply(lambda x: x.shift(1)).fillna(0)\n",
    "\n",
    "    flat_features.loc[:, ['flats_sold_lag', 'flats_value_lag']] = flat_features.loc[:, ['flats_sold_lag', 'flats_value_lag']].fillna(0)\n",
    "    \n",
    "    return flat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1318,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nmurzin/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel/zmqshell.py:537: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "flat_features_active = calc_flat_features(flat_active)\n",
    "flat_features_reserved = calc_flat_features(flat_reserved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1319,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_features = pd.merge(flat_features_active.reset_index(), flat_features_reserved.reset_index(), \n",
    "                         on=['bulk_id', 'spalen', 'date1'], suffixes=('_active', '_reserved'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1320,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_features.to_csv('output/flat_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1321,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_2 = pd.merge(train_test.reset_index(), flat_features.reset_index(), on=['bulk_id', 'spalen', 'date1'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1322,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = pd.read_csv('input/train.csv', encoding='cp1251').drop(\n",
    "    ['start_square', 'price', 'mean_fl', 'mean_sq', 'plan_s', 'plan_m', 'plan_l', 'vid_0', 'vid_1', 'vid_2'], axis=1).columns.tolist() \\\n",
    "    + [c + suffix for c in ['flats_left', 'max_fl', 'max_sq', 'min_fl', 'min_sq', 'mean_fl', 'mean_sq', 'sum_sq', 'max_price', 'min_price', 'mean_price',\n",
    "       'flats_sold', 'flats_sold_lag', 'value_lag'] for suffix in ['_active', '_reserved']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1323,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_2['date1'] = train_test_2.date1.apply(lambda x: int(x.timestamp()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1324,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_2[train_test_2['date1'] <= pd.to_datetime('2018-02-01').timestamp()].sort_values('id').fillna(0).to_csv('input/train2.csv', index=False, columns=columns)\n",
    "# train2[train2['date1'] < pd.to_datetime('2017-12-01').timestamp()].sort_values('id').fillna(0).to_csv('input/train2_train.csv', index=False, columns=columns)\n",
    "# train2[train2['date1'] >= pd.to_datetime('2017-12-01').timestamp()].sort_values('id').fillna(0).to_csv('input/train2_val.csv', index=False, columns=columns)\n",
    "\n",
    "train_test_2.loc[train_test_2['value'].isnull(), 'value'] = 0\n",
    "train_test_2[train_test_2['date1'] > pd.to_datetime('2018-02-01').timestamp()].sort_values('id').fillna(0).to_csv('input/test2.csv', index=False, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
