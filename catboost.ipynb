{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=3, random_state=1337, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "#train\n",
    "train = pd.read_csv('input/train2.csv')\n",
    "# df.drop(['start_square', 'plan_s', 'plan_m', 'plan_l', 'vid_0', 'vid_1', 'vid_2'], axis=1, inplace=True)\n",
    "# df.to_csv(\"./input/train_full.csv\", index=False)\n",
    "\n",
    "#test\n",
    "test = pd.read_csv('input/test2.csv')\n",
    "\n",
    "K = 3\n",
    "\n",
    "kf = KFold(n_splits=K, random_state=1337, shuffle=True)\n",
    "kf.get_n_splits(range(len(train)))\n",
    "\n",
    "print(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'id'),\n",
       " (1, 'bulk_id'),\n",
       " (2, 'spalen'),\n",
       " (3, 'date1'),\n",
       " (4, 'value'),\n",
       " (5, 'month'),\n",
       " (6, 'month_cnt'),\n",
       " (7, 'Класс объекта'),\n",
       " (8, 'Количество помещений'),\n",
       " (9, 'Огорожена территория'),\n",
       " (10, 'Площадь земельного участка'),\n",
       " (11, 'Входные группы'),\n",
       " (12, 'Детский сад'),\n",
       " (13, 'Школа'),\n",
       " (14, 'Поликлиника'),\n",
       " (15, 'ФОК'),\n",
       " (16, 'Спортивная площадка'),\n",
       " (17, 'Автомойка'),\n",
       " (18, 'Кладовые'),\n",
       " (19, 'Колясочные'),\n",
       " (20, 'Кондиционирование'),\n",
       " (21, 'Вентлияция'),\n",
       " (22, 'Лифт'),\n",
       " (23, 'Система мусоротведения'),\n",
       " (24, 'Видеонаблюдение'),\n",
       " (25, 'Подземная парковка'),\n",
       " (26, 'Двор без машин'),\n",
       " (27, 'Машиномест'),\n",
       " (28, 'Площадь пром. зоны в радиусе 500 м'),\n",
       " (29, 'Площадь зеленой зоны в радиусе 500 м'),\n",
       " (30, 'До Кремля'),\n",
       " (31, 'До ТТК(км)'),\n",
       " (32, 'До Садового(км)'),\n",
       " (33, 'До большой дороги на машине(км)'),\n",
       " (34, 'До удобной авторазвязки на машине(км)'),\n",
       " (35, 'До метро пешком(км)'),\n",
       " (36, 'До промки(км)'),\n",
       " (37, 'До парка(км)'),\n",
       " (38, 'До парка пешком(км)'),\n",
       " (39, 'Станций метро от кольца'),\n",
       " (40, 'Площадь двора'),\n",
       " (41, 'Курс'),\n",
       " (42, 'Cтавка по ипотеке'),\n",
       " (43, 'Вклады до 1 года'),\n",
       " (44, 'Вклады от 1 года до 3 лет'),\n",
       " (45, 'Вклады свыше 3 лет'),\n",
       " (46, 'flats_left_active'),\n",
       " (47, 'flats_left_reserved'),\n",
       " (48, 'max_fl_active'),\n",
       " (49, 'max_fl_reserved'),\n",
       " (50, 'max_sq_active'),\n",
       " (51, 'max_sq_reserved'),\n",
       " (52, 'min_fl_active'),\n",
       " (53, 'min_fl_reserved'),\n",
       " (54, 'min_sq_active'),\n",
       " (55, 'min_sq_reserved'),\n",
       " (56, 'mean_fl_active'),\n",
       " (57, 'mean_fl_reserved'),\n",
       " (58, 'mean_sq_active'),\n",
       " (59, 'mean_sq_reserved'),\n",
       " (60, 'sum_sq_active'),\n",
       " (61, 'sum_sq_reserved'),\n",
       " (62, 'max_price_active'),\n",
       " (63, 'max_price_reserved'),\n",
       " (64, 'min_price_active'),\n",
       " (65, 'min_price_reserved'),\n",
       " (66, 'mean_price_active'),\n",
       " (67, 'mean_price_reserved'),\n",
       " (68, 'flats_sold_active'),\n",
       " (69, 'flats_sold_reserved'),\n",
       " (70, 'flats_sold_lag_active'),\n",
       " (71, 'flats_sold_lag_reserved'),\n",
       " (72, 'value_lag_active'),\n",
       " (73, 'value_lag_reserved')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(pd.read_csv('input/train2.csv').columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_index, valid_index) in enumerate(kf.split(range(len(train)), train['bulk_id'])):\n",
    "    train.loc[train_index].sort_values(['bulk_id', 'spalen', 'date1']).to_csv(f\"input/train_{i}.csv\",index=False)\n",
    "    train.loc[valid_index].sort_values(['bulk_id', 'spalen', 'date1']).to_csv(f\"input/valid_{i}.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "TEST_FILE = 'input/test2.csv' #add\n",
    "CD_FILE = 'input/train.cd'\n",
    "\n",
    "test_pool = Pool(TEST_FILE, column_description=CD_FILE, has_header=True, delimiter=\",\")\n",
    "\n",
    "oof = pd.DataFrame({'value': None}, index=train['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = model.get_feature_importance(val_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['flats_left_reserved',\n",
       " 'sum_sq_reserved',\n",
       " 'value_lag_reserved',\n",
       " 'value_lag_active',\n",
       " 'flats_left_active',\n",
       " 'sum_sq_active',\n",
       " 'flats_sold_lag_active',\n",
       " 'До парка(км)',\n",
       " 'spalen',\n",
       " 'До метро пешком(км)',\n",
       " 'flats_sold_lag_reserved',\n",
       " 'bulk_id',\n",
       " 'month',\n",
       " 'Cтавка по ипотеке',\n",
       " 'min_price_reserved',\n",
       " 'До парка пешком(км)',\n",
       " 'До большой дороги на машине(км)',\n",
       " 'Машиномест',\n",
       " 'min_price_active',\n",
       " 'min_sq_reserved',\n",
       " 'Площадь двора',\n",
       " 'Вклады свыше 3 лет',\n",
       " 'Вклады до 1 года',\n",
       " 'mean_sq_active',\n",
       " 'Видеонаблюдение',\n",
       " 'Класс объекта',\n",
       " 'max_price_active',\n",
       " 'max_sq_reserved',\n",
       " 'Поликлиника',\n",
       " 'mean_price_reserved',\n",
       " 'mean_price_active',\n",
       " 'Вентлияция',\n",
       " 'max_sq_active',\n",
       " 'Кладовые',\n",
       " 'mean_fl_reserved',\n",
       " 'max_fl_reserved',\n",
       " 'max_price_reserved',\n",
       " 'max_fl_active',\n",
       " 'mean_fl_active',\n",
       " 'Вклады от 1 года до 3 лет',\n",
       " 'mean_sq_reserved',\n",
       " 'min_sq_active',\n",
       " 'Детский сад',\n",
       " 'Количество помещений',\n",
       " 'Курс',\n",
       " 'До удобной авторазвязки на машине(км)',\n",
       " 'ФОК',\n",
       " 'Площадь земельного участка',\n",
       " 'Школа',\n",
       " 'Площадь зеленой зоны в радиусе 500 м',\n",
       " 'Кондиционирование',\n",
       " 'Площадь пром. зоны в радиусе 500 м',\n",
       " 'Станций метро от кольца',\n",
       " 'До промки(км)',\n",
       " 'min_fl_active',\n",
       " 'Подземная парковка',\n",
       " 'min_fl_reserved',\n",
       " 'До Кремля',\n",
       " 'До ТТК(км)',\n",
       " 'Двор без машин',\n",
       " 'До Садового(км)',\n",
       " 'Колясочные',\n",
       " 'Огорожена территория',\n",
       " 'Входные группы',\n",
       " 'Автомойка',\n",
       " 'Лифт',\n",
       " 'Система мусоротведения',\n",
       " 'Спортивная площадка']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[train_pool.get_feature_names()[i] for i in np.argsort(importance)[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 423.9898431\ttest: 436.0666276\tbest: 436.0666276 (0)\ttotal: 59.5ms\tremaining: 59.4s\n",
      "500:\tlearn: 204.1590529\ttest: 224.2077593\tbest: 224.2077593 (500)\ttotal: 41s\tremaining: 40.8s\n",
      "\n",
      "bestTest = 206.3329246\n",
      "bestIteration = 999\n",
      "\n",
      "Shrink model to first 1000 iterations.\n",
      "0:\tlearn: 421.0218818\ttest: 441.3710680\tbest: 441.3710680 (0)\ttotal: 142ms\tremaining: 2m 21s\n",
      "500:\tlearn: 189.5361221\ttest: 243.0647081\tbest: 243.0647081 (500)\ttotal: 1m 9s\tremaining: 1m 9s\n",
      "\n",
      "bestTest = 233.9327484\n",
      "bestIteration = 999\n",
      "\n",
      "Shrink model to first 1000 iterations.\n",
      "0:\tlearn: 438.5332680\ttest: 406.0139134\tbest: 406.0139134 (0)\ttotal: 117ms\tremaining: 1m 56s\n",
      "500:\tlearn: 198.3294256\ttest: 219.2711398\tbest: 219.2711398 (500)\ttotal: 1m 7s\tremaining: 1m 7s\n",
      "\n",
      "bestTest = 213.005561\n",
      "bestIteration = 999\n",
      "\n",
      "Shrink model to first 1000 iterations.\n"
     ]
    }
   ],
   "source": [
    "for i in range(K):\n",
    "\n",
    "    TRAIN_FILE = f\"input/train_{i}.csv\"\n",
    "    VAL_FILE = f\"input/valid_{i}.csv\"\n",
    "\n",
    "    train_pool = Pool(TRAIN_FILE, column_description=CD_FILE, has_header=True, delimiter=\",\")\n",
    "    val_pool = Pool(VAL_FILE, column_description=CD_FILE, has_header=True, delimiter=\",\")\n",
    "\n",
    "    model = CatBoostRegressor(iterations=1000,\n",
    "                              #n_estimators=1000,\n",
    "                              learning_rate=0.01,\n",
    "                              depth=10,\n",
    "                              #l2_leaf_reg=10,\n",
    "                              random_seed=1337)\n",
    "    \n",
    "    #model = model.load_model(f\"models/value_{i}\")\n",
    "    \n",
    "    model.fit(train_pool, eval_set=val_pool, verbose=500)\n",
    "    model.save_model(f\"models/value_no_reserved_{i}\")\n",
    "    \n",
    "#     pred = model.predict(test_pool)\n",
    "#     test[f\"flats_sold_{i}\"] = pred\n",
    " \n",
    "#     pred = model.predict(val_pool)\n",
    "#     val = pd.read_csv(VAL_FILE, usecols=['id'], index_col='id')\n",
    "#     oof.loc[val.index, 'flats_sold'] = pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dates = test['date1'].apply(dt.fromtimestamp).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "flats_train = pd.read_csv('output/flat_train_predict.csv', \n",
    "                    usecols=['bulk_id', 'spalen', 'id_flatwork', 'floor', 'square', 'pricem2', 'rank'],\n",
    "                    index_col=['bulk_id', 'spalen', 'id_flatwork'])\n",
    "\n",
    "flats_test = pd.read_csv('output/flat_test_predict.csv', \n",
    "                    usecols=['bulk_id', 'spalen', 'id_flatwork', 'floor', 'square', 'pricem2', 'rank'],\n",
    "                    index_col=['bulk_id', 'spalen', 'id_flatwork'])\n",
    "\n",
    "flats = pd.concat([flats_train, flats_test]).groupby(level=[0, 1], group_keys=False) \\\n",
    "    .apply(lambda df: df.sort_values('rank')).join(flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_active = pd.read_csv('output/flat_active.csv', dtype={'spalen': int},\n",
    "                         index_col=['date1', 'bulk_id', 'spalen', 'id_flatwork'], parse_dates=['date1']).sort_index()\n",
    "\n",
    "flat_reserved = pd.read_csv('output/flat_reserved.csv', dtype={'spalen': int},\n",
    "                         index_col=['date1', 'bulk_id', 'spalen', 'id_flatwork'], parse_dates=['date1']).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_active =flat_active.join(flats.reset_index(['bulk_id', 'spalen'])['rank'])\n",
    "flat_reserved = flat_reserved.join(flats.reset_index(['bulk_id', 'spalen'])['rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recalculate_features(df, flats=None, date=None):\n",
    "    idx = (df['bulk_id'].iloc[0], df['spalen'].iloc[0])\n",
    "    \n",
    "    prev_date = (pd.to_datetime(date) - pd.offsets.MonthBegin()).to_datetime64()\n",
    "    \n",
    "    def get_flats_left(flat_data):\n",
    "        available_flats = flat_data.loc[date]\n",
    "        prev_available_flats = flat_data.loc[prev_date]\n",
    "        \n",
    "        if available_flats.index.contains(idx):\n",
    "            available_flats = available_flats.loc[idx]\n",
    "            if prev_available_flats.index.contains(idx):\n",
    "                prev_available_flats = prev_available_flats.loc[idx]\n",
    "                non_available_index = prev_available_flats.index.difference(available_flats.index)\n",
    "                \n",
    "                non_available_flats = prev_available_flats.loc[non_available_index]\n",
    "            else:\n",
    "                non_available_flats = prev_available_flats.iloc[:0]\n",
    "        else:\n",
    "            available_flats = available_flats.iloc[:0]\n",
    "            if prev_available_flats.index.contains(idx):\n",
    "                non_available_flats = prev_available_flats.loc[idx]\n",
    "            else:\n",
    "                non_available_flats = prev_available_flats.iloc[:0]\n",
    "            \n",
    "        if flats.index.contains(idx) :\n",
    "            flats_left = flats.loc[idx]\n",
    "\n",
    "            flats_left = flats_left.loc[flats_left.index.intersection(available_flats.index).difference(non_available_flats.index)]\n",
    "\n",
    "            flats_left = pd.concat([flats_left, non_available_flats])\n",
    "\n",
    "        else:\n",
    "            flats_left = non_available_flats\n",
    "            \n",
    "        flats_left.sort_values('rank', inplace=True)\n",
    "            \n",
    "        return flats_left\n",
    "    \n",
    "    def get_data(flat_data):\n",
    "        \n",
    "        flats_left = get_flats_left(flat_data)\n",
    "            \n",
    "        data_left = flats_left[flats_left['square'].cumsum() > df['value_predict_active'].iloc[0]]\n",
    "        data_sold = flats_left[flats_left['square'].cumsum() <= df['value_predict_active'].iloc[0]]\n",
    "            \n",
    "        return {'flats_left': len(data_left),\n",
    "                'max_fl': data_left['floor'].max(), \n",
    "                'min_fl': data_left['floor'].min(),\n",
    "                'mean_fl': data_left['floor'].mean(),\n",
    "                'max_sq': data_left['square'].max(), \n",
    "                'min_sq': data_left['square'].min(),\n",
    "                'mean_sq': data_left['square'].mean(),\n",
    "                'sum_sq': data_left['square'].sum(),\n",
    "                'max_price': data_left['pricem2'].max(),\n",
    "                'min_price': data_left['pricem2'].min(),\n",
    "                'mean_price': data_left['pricem2'].mean(),\n",
    "                'value_predict': data_sold['square'].sum()}\n",
    "    \n",
    "    data_active = get_data(flat_active)\n",
    "    data_reserved = get_data(flat_reserved)\n",
    "    \n",
    "    result = {k + '_active': v for k, v in data_active.items()}\n",
    "    result.update({k + '_reserved': v for k, v in data_reserved.items()})\n",
    "    \n",
    "    return pd.Series(result)\n",
    "\n",
    "def drop_sold_flats(flats_left, prediction, date):\n",
    "    flats_left_idx = []\n",
    "\n",
    "    prev_date = (pd.to_datetime(date) - pd.offsets.MonthBegin()).to_datetime64()\n",
    "    \n",
    "    def get_flats_left(flat_data, idx):\n",
    "        available_flats = flat_data.loc[date]\n",
    "        prev_available_flats = flat_data.loc[prev_date]\n",
    "        \n",
    "        if available_flats.index.contains(idx):\n",
    "            available_flats = available_flats.loc[idx]\n",
    "            if prev_available_flats.index.contains(idx):\n",
    "                prev_available_flats = prev_available_flats.loc[idx]\n",
    "                non_available_index = prev_available_flats.index.difference(available_flats.index)\n",
    "                \n",
    "                non_available_flats = prev_available_flats.loc[non_available_index]\n",
    "            else:\n",
    "                non_available_flats = prev_available_flats.iloc[:0]\n",
    "        else:\n",
    "            available_flats = available_flats.iloc[:0]\n",
    "            if prev_available_flats.index.contains(idx):\n",
    "                non_available_flats = prev_available_flats.loc[idx]\n",
    "            else:\n",
    "                non_available_flats = prev_available_flats.iloc[:0]\n",
    "            \n",
    "        if flats.index.contains(idx) :\n",
    "            flats_left = flats.loc[idx]\n",
    "\n",
    "            flats_left = flats_left.loc[flats_left.index.intersection(available_flats.index).difference(non_available_flats.index)]\n",
    "\n",
    "            flats_left = pd.concat([flats_left, non_available_flats])\n",
    "\n",
    "        else:\n",
    "            flats_left = non_available_flats\n",
    "            \n",
    "        flats_left.sort_values('rank', inplace=True)\n",
    "            \n",
    "        return flats_left\n",
    "    \n",
    "\n",
    "    for idx, g in flats_left.groupby(level=[0, 1]).groups.items():\n",
    "\n",
    "        df = get_flats_left(flat_active, idx)\n",
    "        \n",
    "        if prediction.index.contains(idx):     \n",
    "            df = df[df['square'].cumsum() > prediction.loc[idx]]\n",
    "            \n",
    "        flats_left_idx.append(pd.concat([df], keys=[idx], names=['id_bulk', 'spalen']))\n",
    "\n",
    "    return pd.concat(flats_left_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a6eabfd87d45ac815fbbb4aa8333cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recalculating features...\n",
      "Dropping flats...\n",
      "Recalculating features...\n",
      "Dropping flats...\n",
      "Recalculating features...\n",
      "Dropping flats...\n"
     ]
    }
   ],
   "source": [
    "flats_left = flats[flats['sale'] >= test_dates[0]]\n",
    "\n",
    "next_flats_left = None\n",
    "next_date_features = None\n",
    "prev_test_date = None\n",
    "\n",
    "test_predict_date = []\n",
    "\n",
    "for date in tqdm_notebook(test_dates):\n",
    "\n",
    "    test_date_file = f\"output/test_date_{date}.csv\"\n",
    "    test_date = test[test['date1'].apply(dt.fromtimestamp) == date].copy()\n",
    "    \n",
    "    if next_flats_left is not None:\n",
    "        flats_left = next_flats_left\n",
    "    \n",
    "    if next_date_features is not None:\n",
    "        cols = [c + suffix for c in ['flats_left', 'mean_fl', 'mean_sq', 'max_fl', 'max_sq', \n",
    "                                     'min_fl', 'min_sq', 'sum_sq',\n",
    "                                     'mean_price', 'max_price', 'min_price'] for suffix in ['_active', '_reserved']]\n",
    "        test_date = pd.merge(test_date.drop(cols, axis=1),\n",
    "                             next_date_features.reset_index(), on=['bulk_id', 'spalen'], how='left')\n",
    "    if prev_test_date is not None:\n",
    "        test_date = pd.merge(test_date.drop([c + suffix for c in ['flats_sold_lag', 'value_lag'] for suffix in ['_active', '_reserved']], axis=1, errors='ignore'),\n",
    "                             prev_test_date.drop([c + suffix for c in ['flats_sold_lag', 'value_lag'] for suffix in ['_active', '_reserved']], axis=1)[['bulk_id', 'spalen', 'flats_sold_active', 'value_predict_active', 'flats_sold_reserved', 'value_predict_reserved']]\n",
    "                                 .rename(columns={'flats_sold_active': 'flats_sold_lag_active', \n",
    "                                                  'value_predict_active': 'value_lag_active',\n",
    "                                                  'flats_sold_reserved': 'flats_sold_lag_reserved', \n",
    "                                                  'value_predict_reserved': 'value_lag_reserved',}), on=['bulk_id', 'spalen'], how='left') \\\n",
    "            .fillna(0)\n",
    "    test_date.to_csv(test_date_file, index=False, columns=test.columns)\n",
    "    \n",
    "    test_pool = Pool(test_date_file, column_description=CD_FILE, has_header=True, delimiter=\",\")\n",
    "\n",
    "    test_date['value_predict_active'] = 0\n",
    "    \n",
    "    for i in range(K):\n",
    "        model = CatBoostRegressor().load_model(f\"models/value_no_reserved_{i}\")\n",
    "        test_date['value_predict_active'] = test_date['value_predict_active'] + model.predict(test_pool)\n",
    "        \n",
    "    test_date['value_predict_active'] = test_date['value_predict_active'] / K\n",
    "\n",
    "    prediction = test_date.set_index(['bulk_id', 'spalen'])['value_predict_active'].sort_index()\n",
    "\n",
    "    print('Recalculating features...')\n",
    "    next_date_features = test_date.groupby(['bulk_id', 'spalen']) \\\n",
    "        .apply(partial(recalculate_features, flats=flats_left, date=date)) \\\n",
    "        .fillna(0)\n",
    "    \n",
    "    #test_date['value_predict_reserved'] = test_date['value_predict_active']\n",
    "    \n",
    "    test_date = pd.merge(test_date.drop(['value_predict_reserved'], axis=1, errors='ignore'),\n",
    "                         next_date_features[['value_predict_reserved']].reset_index(), on=['bulk_id', 'spalen'], how='left')\n",
    "\n",
    "    print('Dropping flats...')\n",
    "    #next_flats_left = drop_sold_flats(flats_left, prediction, date)\n",
    "\n",
    "    \n",
    "    prev_test_date = test_date.copy()\n",
    "    \n",
    "    test_date['date1'] = test_date['date1'].apply(dt.fromtimestamp)\n",
    "    test_predict_date.append(test_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_date_features['date1'] = pd.to_datetime(test_dates[-1]) + pd.offsets.MonthBegin(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['bulk_id', 'spalen', 'date1', 'sum_sq_active', 'value', 'value_predict_active']\n",
    "test_predict = pd.concat(test_predict_date + [next_date_features.reset_index()])[columns].set_index(['bulk_id', 'spalen', 'date1']).sort_index()\n",
    "test_predict.index.set_levels(test_predict.index.levels[2].map(lambda x: int(x.timestamp())), level=2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(test[['bulk_id', 'spalen', 'date1', 'value']], \n",
    "              test_predict.reset_index().drop('value', axis=1), on=['bulk_id', 'spalen', 'date1'], how='left')\n",
    "\n",
    "#df = df[df['date1'].apply(dt.fromtimestamp) == test_dates[0]]\n",
    "#np.sqrt(mean_squared_error(df['value'], df['value_predict']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.merge(test[['id', 'bulk_id', 'spalen', 'date1']], \n",
    "         df[['bulk_id', 'spalen', 'date1', 'value_predict_active']], on=['bulk_id', 'spalen', 'date1'], how='left') \\\n",
    "    .rename(columns={'value_predict_active': 'value'})[['id', 'value']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('output/submission_final_10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = pd.read_csv('output/sample5.csv', index_col=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = pd.read_csv('output/submission_final_6.csv', index_col=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = pd.read_csv('output/submission_final_10.csv', index_col=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = pd.read_csv('/Users/nmurzin/Downloads/sample9.csv', index_col=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = model1.join(model2, lsuffix='_1', rsuffix='_2').join(model4, rsuffix='_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['value_1'] = 0.6 * df['value_1'] \n",
    "df['value_2'] = 0.4 * df['value_2'] \n",
    "#df['value'] = 0.333 * df['value'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['value'] = df[['value_1', 'value_2', 'value']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['value'].reset_index().to_csv('output/submission_mean_weighted_8.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
